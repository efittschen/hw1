{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b8b334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "import psutil\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, TrainerCallback, AutoModelForMaskedLM\n",
    "import random\n",
    "import datasets\n",
    "import wandb\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b420247",
   "metadata": {},
   "source": [
    "### Exercise 4.1\n",
    "\n",
    "Build a classifier based on ModernBERT and fine-tune the classification head only (not the model weights) so that\n",
    "the accuracy is maximized for this task. Plot the accuracy on train and dev (validation) sets over the course of\n",
    "training. Report the results on the test set corresponding to your best model measured on the dev (validation) set\n",
    "in Table 1. Include the results in Table 1. Include a link to your code on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45261752",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d1ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_qa = datasets.load_dataset(\"wics/strategy-qa\", split=\"test\")\n",
    "ds = strategy_qa.train_test_split(test_size=0.2, seed=42, shuffle=True)\n",
    "tv = ds[\"test\"].train_test_split(test_size=0.5, seed=42, shuffle=True)\n",
    "label_map = {\"true\": 1, \"false\": 0}\n",
    "\n",
    "ds = datasets.DatasetDict({\n",
    "    \"train\": ds[\"train\"],\n",
    "    \"test\": tv[\"test\"],\n",
    "    \"validation\": tv[\"train\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a903fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1832\n",
      "Validation size: 229\n",
      "Test size: 229\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(ds['train'])}\")\n",
    "print(f\"Validation size: {len(ds['validation'])}\")\n",
    "print(f\"Test size: {len(ds['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36eed340",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_id = tokenizer(\"true\")[\"input_ids\"][1]\n",
    "false_pos_id = tokenizer(\"false\")[\"input_ids\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77636ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ex):\n",
    "    ans = ex[\"answer\"]\n",
    "    y = int(bool(ans))\n",
    "    # appending facts to the question, because the model is not doing well at all\n",
    "    text = ex[\"question\"] + \" Answer: [MASK]\"\n",
    "    text = \" \".join(ex[\"facts\"]) + \" \" + ex[\"question\"] + \" Answer: [MASK]\"\n",
    "    enc = tokenizer(text, padding=\"max_length\", truncation=True, max_length=145)\n",
    "    mask_position = enc['input_ids'].index(tokenizer.mask_token_id)\n",
    "    labels = enc[\"input_ids\"].copy()\n",
    "    labels[mask_position] = true_pos_id if y == 1 else false_pos_id\n",
    "    enc[\"labels\"] = labels\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b8f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(preprocess, remove_columns=strategy_qa.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b6452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for x in ds[\"test\"]:\n",
    "    max_len = max(max_len, len(x[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2633782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f324d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21bbd71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a04a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a41e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    B, L, V = logits.shape\n",
    "    m = (labels == tokenizer.sep_token_id)\n",
    "    sep_pos = m.argmax(axis=1)\n",
    "    pos = sep_pos - 1\n",
    "    batch_ix = np.arange(B)\n",
    "    step_logits = logits[batch_ix, pos, :]\n",
    "    logits = step_logits[:, [false_pos_id, true_pos_id]]\n",
    "    refs = labels[batch_ix, pos]\n",
    "    refs = (refs == true_pos_id).astype(int)\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4792984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEvalCallback(TrainerCallback):\n",
    "    def __init__(self, trainer, sample_size=229):\n",
    "        self.trainer = trainer\n",
    "        self.sample_size = sample_size\n",
    "        self.train_sample = None\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        ds = self.trainer.train_dataset\n",
    "        self.train_sample = ds.select(range(self.sample_size))\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        metrics = self.trainer.evaluate(\n",
    "            eval_dataset=self.train_sample,\n",
    "            metric_key_prefix=\"train\",\n",
    "            ignore_keys=None,\n",
    "        )\n",
    "        self.trainer.log(metrics)\n",
    "        control.should_evaluate = True\n",
    "        control.should_log = True\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ffe4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1248243/1323077581.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1536\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"modernbert-strategyqa\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.2,\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "def model_init():\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\n",
    "        \"answerdotai/ModernBERT-base\"\n",
    "    )\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    lora_config = LoraConfig(\n",
    "        r=1,\n",
    "        target_modules = [\"attn.Wo\"],\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        layers_to_transform=[16],\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "        if \"lora\" in name:\n",
    "            param.requires_grad = True\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total_trainable_params}\")\n",
    "    return model\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.add_callback(TrainEvalCallback(trainer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2b8278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 23:32:39,583] A new study created in memory with name: no-name-7c28e69a-887a-4f38-869e-7313cce2b5d7\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melisabeth-fittschen\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/efittsc1/projects/hyperparameter_experiments/wandb/run-20250904_233240-k3u78u32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elisabeth-fittschen/huggingface/runs/k3u78u32' target=\"_blank\">fluent-valley-698</a></strong> to <a href='https://wandb.ai/elisabeth-fittschen/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elisabeth-fittschen/huggingface' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elisabeth-fittschen/huggingface/runs/k3u78u32' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/huggingface/runs/k3u78u32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='174' max='174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [174/174 00:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.075900</td>\n",
       "      <td>14.047585</td>\n",
       "      <td>0.550218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.018700</td>\n",
       "      <td>14.047292</td>\n",
       "      <td>0.550218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.275800</td>\n",
       "      <td>14.047220</td>\n",
       "      <td>0.550218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[I 2025-09-04 23:33:17,611] Trial 0 finished with value: 0.5502183406113537 and parameters: {'learning_rate': 5.21122452604712e-06}. Best is trial 0 with value: 0.5502183406113537.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1536\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▁</td></tr><tr><td>eval/loss</td><td>█▂▁</td></tr><tr><td>eval/runtime</td><td>█▁▅</td></tr><tr><td>eval/samples_per_second</td><td>▁█▅</td></tr><tr><td>eval/steps_per_second</td><td>▁█▆</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▃▃▄▄▄▅▅▆▆▆▆▆▆▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▃▃▄▄▄▅▅▆▆▆▆▆▆▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▄▃▄▃▆▄▅▃▄█▄▆█▅▅▆▅</td></tr><tr><td>train/learning_rate</td><td>▃▅▇████▇▆▆▅▄▄▃▃▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▄▃▂▅▅▅▄▄▃▃▃▂▄▁▅▅▃▃▃█</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.55022</td></tr><tr><td>eval/loss</td><td>14.04722</td></tr><tr><td>eval/runtime</td><td>2.5918</td></tr><tr><td>eval/samples_per_second</td><td>88.357</td></tr><tr><td>eval/steps_per_second</td><td>3.087</td></tr><tr><td>total_flos</td><td>530625089018880.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>174</td></tr><tr><td>train/grad_norm</td><td>1669.03589</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-valley-698</strong> at: <a href='https://wandb.ai/elisabeth-fittschen/huggingface/runs/k3u78u32' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/huggingface/runs/k3u78u32</a><br> View project at: <a href='https://wandb.ai/elisabeth-fittschen/huggingface' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_233240-k3u78u32/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/efittsc1/projects/hyperparameter_experiments/wandb/run-20250904_233318-p4vlgg0c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elisabeth-fittschen/huggingface/runs/p4vlgg0c' target=\"_blank\">ancient-water-699</a></strong> to <a href='https://wandb.ai/elisabeth-fittschen/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elisabeth-fittschen/huggingface' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elisabeth-fittschen/huggingface/runs/p4vlgg0c' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/huggingface/runs/p4vlgg0c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='174' max='174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [174/174 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.766900</td>\n",
       "      <td>13.281297</td>\n",
       "      <td>0.519651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.697700</td>\n",
       "      <td>11.293640</td>\n",
       "      <td>0.493450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.615500</td>\n",
       "      <td>10.819053</td>\n",
       "      <td>0.475983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "[I 2025-09-04 23:33:53,176] Trial 1 finished with value: 0.4759825327510917 and parameters: {'learning_rate': 0.0006553429689433842}. Best is trial 0 with value: 0.5502183406113537.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='0', objective=0.5502183406113537, hyperparameters={'learning_rate': 5.21122452604712e-06}, run_summary=None)\n"
     ]
    }
   ],
   "source": [
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-6, 5e-3, log=True),\n",
    "    }\n",
    "\n",
    "best = trainer.hyperparameter_search(\n",
    "    backend=\"optuna\",\n",
    "    direction=\"maximize\",\n",
    "    n_trials=2,\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda m: m[\"eval_accuracy\"],\n",
    ")\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5afd00de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1248243/2642406193.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='174' max='174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [174/174 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.075900</td>\n",
       "      <td>14.047539</td>\n",
       "      <td>0.550218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.018700</td>\n",
       "      <td>14.047336</td>\n",
       "      <td>0.550218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.275800</td>\n",
       "      <td>14.047254</td>\n",
       "      <td>0.550218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 13.780497550964355,\n",
       " 'eval_accuracy': 0.611353711790393,\n",
       " 'eval_runtime': 2.5805,\n",
       " 'eval_samples_per_second': 88.742,\n",
       " 'eval_steps_per_second': 3.1,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"modernbert-strategyqa-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=best.hyperparameters[\"learning_rate\"],\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.add_callback(TrainEvalCallback(trainer))\n",
    "trainer.train()\n",
    "trainer.evaluate(ds[\"validation\"])\n",
    "trainer.evaluate(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb84be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 14.047538757324219, 'eval_accuracy': 0.5502183406113537, 'eval_runtime': 2.5815, 'eval_samples_per_second': 88.707, 'eval_steps_per_second': 3.099, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/hyperparameter_experiments/.venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.780497550964355, 'eval_accuracy': 0.611353711790393, 'eval_runtime': 2.5823, 'eval_samples_per_second': 88.68, 'eval_steps_per_second': 3.098, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# get test set results\n",
    "print(trainer.evaluate(ds[\"validation\"]))\n",
    "print(trainer.evaluate(ds[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "314bc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cf953e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m.named_parameters():\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_.data.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, _ in model.named_parameters():\n",
    "    print(f\"{name}, {_.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f6f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,920 || all params: 149,657,152 || trainable%: 0.0013\n"
     ]
    }
   ],
   "source": [
    "lora_model = AutoModelForMaskedLM.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\"\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    target_modules = [\"mlp.Wo\"],\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    layers_to_transform=[16],\n",
    ")\n",
    "lora_model = get_peft_model(lora_model, lora_config)\n",
    "for name, param in lora_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(param.data.shape)\n",
    "        param.requires_grad = False\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embeddings.tok_embeddings.weight, False, torch.Size([50368, 768])\n",
      "base_model.model.model.embeddings.norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.0.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.0.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.0.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.0.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.0.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.1.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.1.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.1.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.1.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.1.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.1.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.2.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.2.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.2.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.2.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.2.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.2.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.3.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.3.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.3.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.3.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.3.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.3.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.4.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.4.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.4.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.4.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.4.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.4.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.5.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.5.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.5.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.5.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.5.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.5.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.6.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.6.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.6.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.6.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.6.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.6.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.7.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.7.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.7.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.7.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.7.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.7.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.8.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.8.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.8.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.8.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.8.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.8.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.9.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.9.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.9.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.9.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.9.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.9.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.10.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.10.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.10.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.10.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.10.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.10.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.11.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.11.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.11.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.11.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.11.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.11.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.12.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.12.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.12.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.12.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.12.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.12.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.13.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.13.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.13.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.13.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.13.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.13.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.14.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.14.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.14.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.14.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.14.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.14.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.15.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.15.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.15.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.15.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.15.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.15.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.16.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.16.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.16.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.16.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.16.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.16.mlp.Wo.base_layer.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.16.mlp.Wo.lora_A.default.weight, True, torch.Size([1, 1152])\n",
      "base_model.model.model.layers.16.mlp.Wo.lora_B.default.weight, True, torch.Size([768, 1])\n",
      "base_model.model.model.layers.17.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.17.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.17.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.17.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.17.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.17.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.18.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.18.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.18.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.18.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.18.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.18.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.19.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.19.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.19.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.19.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.19.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.19.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.20.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.20.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.20.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.20.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.20.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.20.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.layers.21.attn_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.21.attn.Wqkv.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.21.attn.Wo.weight, False, torch.Size([768, 768])\n",
      "base_model.model.model.layers.21.mlp_norm.weight, False, torch.Size([768])\n",
      "base_model.model.model.layers.21.mlp.Wi.weight, False, torch.Size([2304, 768])\n",
      "base_model.model.model.layers.21.mlp.Wo.weight, False, torch.Size([768, 1152])\n",
      "base_model.model.model.final_norm.weight, False, torch.Size([768])\n",
      "base_model.model.head.dense.weight, False, torch.Size([768, 768])\n",
      "base_model.model.head.norm.weight, False, torch.Size([768])\n",
      "base_model.model.decoder.bias, False, torch.Size([50368])\n"
     ]
    }
   ],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    print(f\"{name}, {param.requires_grad}, {param.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18378752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.16.mlp.Wo.lora_A.default.weight\n",
      "torch.Size([1, 1152])\n",
      "base_model.model.model.layers.16.mlp.Wo.lora_B.default.weight\n",
      "torch.Size([768, 1])\n",
      "torch.Size([768, 1152])\n"
     ]
    }
   ],
   "source": [
    "for name, param in lora_model.named_parameters():\n",
    "    if \"layers.21.mlp.Wo\" in name:\n",
    "        print(param.data.shape)\n",
    "    if param.requires_grad == True:\n",
    "        print(name)\n",
    "        print(param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a986e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [50281, 5804, 14963, 20754, 11819, 16916, 4647, 521, 1442, 6850, 281, 247, 278, 1657, 24563, 32, 50282], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
